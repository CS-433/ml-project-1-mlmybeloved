{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce48c91",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e36b7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf590b",
   "metadata": {},
   "source": [
    "## Checking the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2c623a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample: [ 1.38470e+02  5.16550e+01  9.78270e+01  2.79800e+01  9.10000e-01\n",
      "  1.24711e+02  2.66600e+00  3.06400e+00  4.19280e+01  1.97760e+02\n",
      "  1.58200e+00  1.39600e+00  2.00000e-01  3.26380e+01  1.01700e+00\n",
      "  3.81000e-01  5.16260e+01  2.27300e+00 -2.41400e+00  1.68240e+01\n",
      " -2.77000e-01  2.58733e+02  2.00000e+00  6.74350e+01  2.15000e+00\n",
      "  4.44000e-01  4.60620e+01  1.24000e+00 -2.47500e+00  1.13497e+02]\n",
      "First sample label: 1\n"
     ]
    }
   ],
   "source": [
    "# Long running\n",
    "y, x = load_data(train=True)\n",
    "print(f\"First sample: {x[0,:]}\")\n",
    "print(f\"First sample label: {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8ab06",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2974608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "\n",
      "X normalized:\n",
      " [[-1.41421356]\n",
      " [-0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n",
      "\n",
      "X with bias:\n",
      " [[ 1.         -1.41421356]\n",
      " [ 1.         -0.70710678]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.70710678]\n",
      " [ 1.          1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "# Define some test data\n",
    "testing_y = np.array([1,1,2,2,4])\n",
    "testing_x = np.array([[1],[2],[3],[4],[5]])\n",
    "testing_w = np.array([-0.1, 0.7])\n",
    "\n",
    "print(f\"X:\\n {testing_x}\\n\")\n",
    "testing_sx, testing_mean_x, testing_std_x = standardize(testing_x) # Standardization\n",
    "print(f\"X normalized:\\n {testing_sx}\\n\") \n",
    "testing_tx = add_x_bias(testing_sx) # Adding bias column to X\n",
    "print(f\"X with bias:\\n {testing_tx}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53571c",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db60e35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE TEST\n",
      "Got:4.714070708874368\n",
      "Expected:4.71\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE TEST\")\n",
    "print(f\"Got:{compute_mse(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str(4.71))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6857fad",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb8337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE TEST\n",
      "Got:2.1\n",
      "Expected:2.1\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE TEST\")\n",
    "print(f\"Got:{compute_mae(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str(2.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d79bf",
   "metadata": {},
   "source": [
    "### MSE Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e397eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Gradient TEST\n",
      "Got:[-2.1        -0.28994949]\n",
      "Expected:[-2.1, -0.29]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE Gradient TEST\")\n",
    "print(f\"Got:{compute_mse_gradient(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str([-2.1, -0.29]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1cbe",
   "metadata": {},
   "source": [
    "### MAE Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b45a485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Gradient TEST\n",
      "Got:[-1.  0.]\n",
      "Expected:[-1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE Gradient TEST\")\n",
    "print(f\"Got:{compute_mae_gradient(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str([-1, -0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8eeb2",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af40ee",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37127a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a single cell because it takes a long time and doesn't need to be ran everytime\n",
    "y, x = load_data(train=True) # Load data\n",
    "y_indexes, x_test = load_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9e2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(x, y, 0.8, np.random.seed())\n",
    "x_tr = replace_min_999_by_col_mean(x_tr) # Handle invalid values\n",
    "x_te = replace_min_999_by_col_mean(x_te)\n",
    "\n",
    "x_tr, mean_x_tr, std_x_tr = standardize(x_tr) # Standardize x\n",
    "x_te, mean_x_te, std_x_te = standardize(x_te)\n",
    "\n",
    "tx_tr = build_poly(x_tr, 2) # build polynomial expansion (with bias)\n",
    "tx_te = build_poly(x_te, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04e81f",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3baccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Training loss: 0.943567673744894 Test loss: 0.943881784478454\n",
      "Epoch 1 : Training loss: 0.9114826520788203 Test loss: 0.9121161479828265\n",
      "Epoch 2 : Training loss: 0.888250851577642 Test loss: 0.8890734585604017\n",
      "Epoch 3 : Training loss: 0.8695817106198759 Test loss: 0.8704946782556624\n",
      "Epoch 4 : Training loss: 0.8538674799533076 Test loss: 0.8547958762033662\n",
      "Epoch 5 : Training loss: 0.840330149796924 Test loss: 0.8412193711918793\n",
      "Epoch 6 : Training loss: 0.8285055573071025 Test loss: 0.8293180518868092\n",
      "Epoch 7 : Training loss: 0.8180748970321832 Test loss: 0.8187863846647297\n",
      "Epoch 8 : Training loss: 0.8088006620957201 Test loss: 0.8093965820124553\n",
      "Epoch 9 : Training loss: 0.8004978111738148 Test loss: 0.8009704290729642\n",
      "Epoch 10 : Training loss: 0.7930184225804165 Test loss: 0.7933646623367039\n",
      "Epoch 11 : Training loss: 0.7862423210372638 Test loss: 0.7864622146858421\n",
      "Epoch 12 : Training loss: 0.7800707714602725 Test loss: 0.7801663803575768\n",
      "Epoch 13 : Training loss: 0.774421962271747 Test loss: 0.7743966370698435\n",
      "Epoch 14 : Training loss: 0.7692276379457196 Test loss: 0.7690855148161431\n",
      "Epoch 15 : Training loss: 0.7644305203216771 Test loss: 0.764176179380382\n",
      "Epoch 16 : Training loss: 0.7599822963269739 Test loss: 0.7596205307172326\n",
      "Epoch 17 : Training loss: 0.7558420254461735 Test loss: 0.7553776858635738\n",
      "Epoch 18 : Training loss: 0.7519748654560595 Test loss: 0.751412756250556\n",
      "Epoch 19 : Training loss: 0.7483510437212716 Test loss: 0.7476958544287092\n",
      "Epoch 20 : Training loss: 0.7449450205843259 Test loss: 0.7442012819306936\n",
      "Epoch 21 : Training loss: 0.7417348047244747 Test loss: 0.7409068616246821\n",
      "Epoch 22 : Training loss: 0.7387013898750228 Test loss: 0.737793386281524\n",
      "Epoch 23 : Training loss: 0.7358282892291259 Test loss: 0.7348441612581603\n",
      "Epoch 24 : Training loss: 0.7331011490200863 Test loss: 0.7320446238504235\n",
      "Epoch 25 : Training loss: 0.7305074266519266 Test loss: 0.7293820254217886\n",
      "Epoch 26 : Training loss: 0.7280361217294109 Test loss: 0.7268451651631036\n",
      "Epoch 27 : Training loss: 0.7256775506358774 Test loss: 0.7244241664859269\n",
      "Epoch 28 : Training loss: 0.7234231571031892 Test loss: 0.7221102887450075\n",
      "Epoch 29 : Training loss: 0.7212653526336723 Test loss: 0.7198957683301461\n",
      "Epoch 30 : Training loss: 0.7191973817586836 Test loss: 0.717773684243155\n",
      "Epoch 31 : Training loss: 0.7172132080186319 Test loss: 0.7157378441410617\n",
      "Epoch 32 : Training loss: 0.7153074172744014 Test loss: 0.7137826875269677\n",
      "Epoch 33 : Training loss: 0.7134751355476159 Test loss: 0.7119032033394421\n",
      "Epoch 34 : Training loss: 0.7117119590656105 Test loss: 0.7100948596565252\n",
      "Epoch 35 : Training loss: 0.7100138945784127 Test loss: 0.7083535436119799\n",
      "Epoch 36 : Training loss: 0.7083773083365666 Test loss: 0.7066755099355518\n",
      "Epoch 37 : Training loss: 0.706798882383728 Test loss: 0.7050573367884321\n",
      "Epoch 38 : Training loss: 0.7052755770371906 Test loss: 0.7034958877800451\n",
      "Epoch 39 : Training loss: 0.7038045986113735 Test loss: 0.7019882792307843\n",
      "Epoch 40 : Training loss: 0.7023833715904604 Test loss: 0.7005318518939344\n",
      "Epoch 41 : Training loss: 0.7010095145824172 Test loss: 0.6991241464740051\n",
      "Epoch 42 : Training loss: 0.6996808194917847 Test loss: 0.6977628823823533\n",
      "Epoch 43 : Training loss: 0.6983952334366581 Test loss: 0.6964459392577534\n",
      "Epoch 44 : Training loss: 0.6971508430089741 Test loss: 0.6951713408523681\n",
      "Epoch 45 : Training loss: 0.695945860539078 Test loss: 0.6939372409447041\n",
      "Epoch 46 : Training loss: 0.6947786120774941 Test loss: 0.6927419109925587\n",
      "Epoch 47 : Training loss: 0.6936475268505274 Test loss: 0.6915837292822485\n",
      "Epoch 48 : Training loss: 0.6925511279831184 Test loss: 0.6904611713669315\n",
      "Epoch 49 : Training loss: 0.6914880243133914 Test loss: 0.6893728016176169\n",
      "Epoch 50 : Training loss: 0.6904569031495076 Test loss: 0.6883172657365116\n",
      "Epoch 51 : Training loss: 0.6894565238415457 Test loss: 0.687293284104354\n",
      "Epoch 52 : Training loss: 0.688485712059822 Test loss: 0.6862996458520303\n",
      "Epoch 53 : Training loss: 0.6875433546868815 Test loss: 0.6853352035625745\n",
      "Epoch 54 : Training loss: 0.6866283952437882 Test loss: 0.6843988685230512\n",
      "Epoch 55 : Training loss: 0.6857398297827164 Test loss: 0.6834896064572104\n",
      "Epoch 56 : Training loss: 0.6848767031874771 Test loss: 0.6826064336794881\n",
      "Epoch 57 : Training loss: 0.6840381058318176 Test loss: 0.6817484136191584\n",
      "Epoch 58 : Training loss: 0.6832231705523072 Test loss: 0.6809146536704727\n",
      "Epoch 59 : Training loss: 0.6824310698985419 Test loss: 0.6801043023306079\n",
      "Epoch 60 : Training loss: 0.6816610136284847 Test loss: 0.679316546592367\n",
      "Epoch 61 : Training loss: 0.6809122464210579 Test loss: 0.6785506095629447\n",
      "Epoch 62 : Training loss: 0.6801840457818081 Test loss: 0.6778057482838266\n",
      "Epoch 63 : Training loss: 0.6794757201206166 Test loss: 0.6770812517301013\n",
      "Epoch 64 : Training loss: 0.6787866069831405 Test loss: 0.6763764389702189\n",
      "Epoch 65 : Training loss: 0.6781160714199864 Test loss: 0.675690657469616\n",
      "Epoch 66 : Training loss: 0.6774635044796239 Test loss: 0.6750232815236552\n",
      "Epoch 67 : Training loss: 0.6768283218127539 Test loss: 0.6743737108071061\n",
      "Epoch 68 : Training loss: 0.6762099623773418 Test loss: 0.6737413690289068\n",
      "Epoch 69 : Training loss: 0.6756078872347873 Test loss: 0.6731257026822733\n",
      "Epoch 70 : Training loss: 0.6750215784288341 Test loss: 0.6725261798813593\n",
      "Epoch 71 : Training loss: 0.6744505379397601 Test loss: 0.6719422892766728\n",
      "Epoch 72 : Training loss: 0.6738942867072301 Test loss: 0.6713735390423085\n",
      "Epoch 73 : Training loss: 0.6733523637159328 Test loss: 0.6708194559288226\n",
      "Epoch 74 : Training loss: 0.6728243251387287 Test loss: 0.6702795843762264\n",
      "Epoch 75 : Training loss: 0.6723097435326124 Test loss: 0.6697534856821519\n",
      "Epoch 76 : Training loss: 0.6718082070832694 Test loss: 0.669240737220759\n",
      "Epoch 77 : Training loss: 0.6713193188944259 Test loss: 0.6687409317083869\n",
      "Epoch 78 : Training loss: 0.6708426963185755 Test loss: 0.6682536765123506\n",
      "Epoch 79 : Training loss: 0.6703779703259868 Test loss: 0.667778592999634\n",
      "Epoch 80 : Training loss: 0.6699247849091936 Test loss: 0.6673153159225267\n",
      "Epoch 81 : Training loss: 0.6694827965204254 Test loss: 0.666863492838535\n",
      "Epoch 82 : Training loss: 0.669051673539665 Test loss: 0.6664227835621348\n",
      "Epoch 83 : Training loss: 0.6686310957712189 Test loss: 0.6659928596461459\n",
      "Epoch 84 : Training loss: 0.6682207539668882 Test loss: 0.6655734038907068\n",
      "Epoch 85 : Training loss: 0.6678203493739558 Test loss: 0.665164109877998\n",
      "Epoch 86 : Training loss: 0.6674295933063918 Test loss: 0.6647646815310128\n",
      "Epoch 87 : Training loss: 0.6670482067377741 Test loss: 0.6643748326948207\n",
      "Epoch 88 : Training loss: 0.6666759199145676 Test loss: 0.6639942867388876\n",
      "Epoch 89 : Training loss: 0.6663124719884926 Test loss: 0.6636227761791336\n",
      "Epoch 90 : Training loss: 0.6659576106668205 Test loss: 0.6632600423185054\n",
      "Epoch 91 : Training loss: 0.665611091879517 Test loss: 0.6629058349049458\n",
      "Epoch 92 : Training loss: 0.6652726794622358 Test loss: 0.6625599118057073\n",
      "Epoch 93 : Training loss: 0.6649421448542335 Test loss: 0.6622220386970522\n",
      "Epoch 94 : Training loss: 0.6646192668103496 Test loss: 0.6618919887684415\n",
      "Epoch 95 : Training loss: 0.6643038311262454 Test loss: 0.6615695424403751\n",
      "Epoch 96 : Training loss: 0.6639956303761647 Test loss: 0.661254487095118\n",
      "Epoch 97 : Training loss: 0.6636944636625126 Test loss: 0.6609466168195819\n",
      "Epoch 98 : Training loss: 0.6634001363766114 Test loss: 0.6606457321596968\n",
      "Epoch 99 : Training loss: 0.6631124599700241 Test loss: 0.6603516398856432\n"
     ]
    }
   ],
   "source": [
    "# We run GD step times per epoch, for epochs epochs (same as running GD for epochs*step just lets us print intermediate results)\n",
    "w_GD, epochs, step, gamma = np.zeros(61), 100, 100, 1e-4\n",
    "loss_tr_GD = []\n",
    "loss_te_GD = []\n",
    "for i in range((int)(epochs)):\n",
    "    w_GD, loss_tr = least_squares_GD(y_tr, tx_tr, w_GD, step, gamma)\n",
    "    loss_te = compute_mse(y_te, tx_te, w_GD)\n",
    "    loss_tr_GD.append(loss_tr)\n",
    "    loss_te_GD.append(loss_te)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a94377",
   "metadata": {},
   "source": [
    "#### Plotting the resulting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10adec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a78acc3280>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(loss_tr_GD)), loss_tr_GD, c='red')\n",
    "plt.plot(range(len(loss_te_GD)), loss_te_GD, c='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549d116",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = -1 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd7ed80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for these w: 75.77199999999999%\n"
     ]
    }
   ],
   "source": [
    "accuracy = compute_accuracy(tx_te, y_te, w_GD, 0)\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70bc433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test, mean_x_test, std_x_test = standardize(x_test) # Standardize x\n",
    "\n",
    "tx_test = build_poly(x_test, 2) # build polynomial expansion (with bias)\n",
    "\n",
    "y_hat = build_prediction(tx_test, w_GD, 0.4)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9588c",
   "metadata": {},
   "source": [
    "### Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40630c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Training loss: 0.32004029743145934 Test loss: 0.3188516426038994\n",
      "Epoch 1 : Training loss: 0.3158255116133148 Test loss: 0.3145061929637362\n",
      "Epoch 2 : Training loss: 0.3134461420413964 Test loss: 0.31201124451384593\n",
      "Epoch 3 : Training loss: 0.31291591204369024 Test loss: 0.3114902770714836\n",
      "Epoch 4 : Training loss: 0.30965924557360053 Test loss: 0.3078879255745183\n",
      "Epoch 5 : Training loss: 0.30906381369523034 Test loss: 0.30713081705529705\n",
      "Epoch 6 : Training loss: 0.30657664431750986 Test loss: 0.30443525155682827\n",
      "Epoch 7 : Training loss: 0.3059970601881488 Test loss: 0.30358291356420225\n",
      "Epoch 8 : Training loss: 0.30448641567911006 Test loss: 0.30188436070658636\n",
      "Epoch 9 : Training loss: 0.3037338490311694 Test loss: 0.30076862812113064\n",
      "Epoch 10 : Training loss: 0.3041445790838162 Test loss: 0.2996327489269914\n",
      "Epoch 11 : Training loss: 0.3041545203041761 Test loss: 0.2995724920371117\n",
      "Epoch 12 : Training loss: 0.304020388509992 Test loss: 0.2980766911529202\n",
      "Epoch 13 : Training loss: 0.3038636226696449 Test loss: 0.2976561902020877\n",
      "Epoch 14 : Training loss: 0.30335175532521563 Test loss: 0.2966094315507379\n",
      "Epoch 15 : Training loss: 0.30290593960431433 Test loss: 0.29595598869913425\n",
      "Epoch 16 : Training loss: 0.30196844609161744 Test loss: 0.29430020834654613\n",
      "Epoch 17 : Training loss: 0.30201541653384595 Test loss: 0.2939697751641475\n",
      "Epoch 18 : Training loss: 0.30277875861518727 Test loss: 0.2931698557268472\n",
      "Epoch 19 : Training loss: 0.302689370274598 Test loss: 0.2932794425613461\n",
      "Epoch 20 : Training loss: 0.30214612429325033 Test loss: 0.2926742123657149\n",
      "Epoch 21 : Training loss: 0.30144443629756895 Test loss: 0.29214586599797204\n",
      "Epoch 22 : Training loss: 0.3014128955917616 Test loss: 0.2915708716984526\n",
      "Epoch 23 : Training loss: 0.301864400773578 Test loss: 0.2918248796754811\n",
      "Epoch 24 : Training loss: 0.3015903921551609 Test loss: 0.29161120836168947\n",
      "Epoch 25 : Training loss: 0.3014857247276524 Test loss: 0.29105256812837216\n",
      "Epoch 26 : Training loss: 0.3008608126908517 Test loss: 0.29024934445843387\n",
      "Epoch 27 : Training loss: 0.3006606759310654 Test loss: 0.2901085777425496\n",
      "Epoch 28 : Training loss: 0.30090988689245973 Test loss: 0.28981897965715103\n",
      "Epoch 29 : Training loss: 0.3002310372580565 Test loss: 0.28866894547118005\n",
      "Epoch 30 : Training loss: 0.3002213835047431 Test loss: 0.2885655532847589\n",
      "Epoch 31 : Training loss: 0.2998301236027259 Test loss: 0.28835505967494995\n",
      "Epoch 32 : Training loss: 0.2997638681524595 Test loss: 0.2879497654703801\n",
      "Epoch 33 : Training loss: 0.299565526594732 Test loss: 0.28744566865656374\n",
      "Epoch 34 : Training loss: 0.2993985712368138 Test loss: 0.2870377560492909\n",
      "Epoch 35 : Training loss: 0.29956735280520597 Test loss: 0.28689904493954116\n",
      "Epoch 36 : Training loss: 0.29920446045113824 Test loss: 0.28594700916052346\n",
      "Epoch 37 : Training loss: 0.2988664095864221 Test loss: 0.2858196966406809\n",
      "Epoch 38 : Training loss: 0.29875729281582025 Test loss: 0.2856507888208005\n",
      "Epoch 39 : Training loss: 0.299320899708038 Test loss: 0.28532277710307924\n",
      "Epoch 40 : Training loss: 0.2989296205453568 Test loss: 0.2848849117085741\n",
      "Epoch 41 : Training loss: 0.29889549069811616 Test loss: 0.2847877263832857\n",
      "Epoch 42 : Training loss: 0.2987039003586636 Test loss: 0.2844713641686956\n",
      "Epoch 43 : Training loss: 0.2989149695718342 Test loss: 0.2843882686027017\n",
      "Epoch 44 : Training loss: 0.29896154161733474 Test loss: 0.28440585581033007\n",
      "Epoch 45 : Training loss: 0.29862191124637116 Test loss: 0.2841457172400418\n",
      "Epoch 46 : Training loss: 0.2983814447558572 Test loss: 0.2839694737712068\n",
      "Epoch 47 : Training loss: 0.2986043317578449 Test loss: 0.2836528874506803\n",
      "Epoch 48 : Training loss: 0.2983905294174915 Test loss: 0.2832590788451668\n",
      "Epoch 49 : Training loss: 0.2982770344112347 Test loss: 0.28313393673496917\n",
      "Epoch 50 : Training loss: 0.298573961148349 Test loss: 0.28278311805641104\n",
      "Epoch 51 : Training loss: 0.29844027019303704 Test loss: 0.28248647659897147\n",
      "Epoch 52 : Training loss: 0.30003900685760926 Test loss: 0.2823703529632949\n",
      "Epoch 53 : Training loss: 0.29976694070613324 Test loss: 0.28194153806456773\n",
      "Epoch 54 : Training loss: 0.2995848925067422 Test loss: 0.2814769729862285\n",
      "Epoch 55 : Training loss: 0.29940747754027314 Test loss: 0.281501785358093\n",
      "Epoch 56 : Training loss: 0.299383071038631 Test loss: 0.2811646551874382\n",
      "Epoch 57 : Training loss: 0.2986644726961298 Test loss: 0.2806515871948267\n",
      "Epoch 58 : Training loss: 0.2989613003510435 Test loss: 0.28048059840742084\n",
      "Epoch 59 : Training loss: 0.300050710060788 Test loss: 0.28013236866782065\n",
      "Epoch 60 : Training loss: 0.30006136495587765 Test loss: 0.2800179058735379\n",
      "Epoch 61 : Training loss: 0.3005422215720783 Test loss: 0.27994589772528594\n",
      "Epoch 62 : Training loss: 0.30091394301485624 Test loss: 0.27961884311894836\n",
      "Epoch 63 : Training loss: 0.301234867669116 Test loss: 0.27937587264506153\n",
      "Epoch 64 : Training loss: 0.30255114239045383 Test loss: 0.27945305889593197\n",
      "Epoch 65 : Training loss: 0.30251795373172297 Test loss: 0.2792489944086607\n",
      "Epoch 66 : Training loss: 0.3028586882851324 Test loss: 0.27898151846618213\n",
      "Epoch 67 : Training loss: 0.3027981241144238 Test loss: 0.27901208628610225\n",
      "Epoch 68 : Training loss: 0.3022023341845329 Test loss: 0.2790050397165964\n",
      "Epoch 69 : Training loss: 0.3017855742400377 Test loss: 0.278691436116863\n",
      "Epoch 70 : Training loss: 0.30061454581356767 Test loss: 0.2785810466057766\n",
      "Epoch 71 : Training loss: 0.3001789917714573 Test loss: 0.27841141467959285\n",
      "Epoch 72 : Training loss: 0.3008753668276811 Test loss: 0.2781539811404392\n",
      "Epoch 73 : Training loss: 0.30090167723069644 Test loss: 0.27797903587826833\n",
      "Epoch 74 : Training loss: 0.30341234618378565 Test loss: 0.2778265685687267\n",
      "Epoch 75 : Training loss: 0.3031245361396047 Test loss: 0.27766208836702455\n",
      "Epoch 76 : Training loss: 0.30621575636855136 Test loss: 0.28603373689244505\n",
      "Epoch 77 : Training loss: 0.30644044438366175 Test loss: 0.28544884780324237\n",
      "Epoch 78 : Training loss: 0.30648089439145865 Test loss: 0.285250988861099\n",
      "Epoch 79 : Training loss: 0.3064322261597761 Test loss: 0.28524550881107585\n",
      "Epoch 80 : Training loss: 0.3059190693398877 Test loss: 0.2843993862324588\n",
      "Epoch 81 : Training loss: 0.30634556943143265 Test loss: 0.28401466214074234\n",
      "Epoch 82 : Training loss: 0.30591989322481 Test loss: 0.2839916824907125\n",
      "Epoch 83 : Training loss: 0.3057603801018631 Test loss: 0.28371475701289056\n",
      "Epoch 84 : Training loss: 0.3057016044155347 Test loss: 0.2835315914222173\n",
      "Epoch 85 : Training loss: 0.3057562317981987 Test loss: 0.28340001070021525\n",
      "Epoch 86 : Training loss: 0.30578760726813853 Test loss: 0.2833757393462644\n",
      "Epoch 87 : Training loss: 0.30563933060047804 Test loss: 0.28302458812903075\n",
      "Epoch 88 : Training loss: 0.3056637416142436 Test loss: 0.28299336030155425\n",
      "Epoch 89 : Training loss: 0.30554973322222995 Test loss: 0.2829261056766817\n",
      "Epoch 90 : Training loss: 0.3055485160620144 Test loss: 0.28288827538695066\n",
      "Epoch 91 : Training loss: 0.3055284010058105 Test loss: 0.28282556620836075\n",
      "Epoch 92 : Training loss: 0.30628122962215415 Test loss: 0.28193916713089756\n",
      "Epoch 93 : Training loss: 0.3063610693786187 Test loss: 0.28193282244231294\n",
      "Epoch 94 : Training loss: 0.30711424991559544 Test loss: 0.28174583894520383\n",
      "Epoch 95 : Training loss: 0.3073121450090706 Test loss: 0.281350036510609\n",
      "Epoch 96 : Training loss: 0.3079516645867726 Test loss: 0.27944296371246513\n",
      "Epoch 97 : Training loss: 0.30886153529285915 Test loss: 0.279071037822809\n",
      "Epoch 98 : Training loss: 0.30882578865846166 Test loss: 0.2788838191089093\n",
      "Epoch 99 : Training loss: 0.30978929513944004 Test loss: 0.2785291103828727\n"
     ]
    }
   ],
   "source": [
    "w_SGD, epochs, step, gamma = np.zeros(61), 100, 100, 1e-4\n",
    "for i in range((int)(epochs)):\n",
    "    w_SGD, loss_tr = least_squares_SGD(y_tr, tx_tr, w_SGD, step, gamma)\n",
    "    loss_te = compute_mse(y_te, tx_te, w_SGD)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120442c2",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ac680a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for these w: 67.24799999999999%\n"
     ]
    }
   ],
   "source": [
    "y_hat_cont = tx_te@w_SGD\n",
    "y_hat = [1 if yi > 0.40 else 0 for yi in y_hat_cont]\n",
    "accuracy = 1-abs(y_te-y_hat).mean()\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c498d12",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3729fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.15775399909190493\n",
      "Test loss: 1.0311299950200723\n",
      "w: [ 3.37137664e-01  6.52970377e-02 -1.22701137e-01 -1.52811873e-01\n",
      "  7.14286545e-02 -2.48003253e-02 -1.22351877e-02 -3.23113961e-02\n",
      "  1.31578040e-01 -5.80539364e-03 -2.24032327e+02 -9.88973360e-02\n",
      "  2.14275181e-02  3.53804357e-02  4.34080174e+01  5.00657117e-04\n",
      "  3.13543582e-04  4.26889017e+01  6.03112117e-05  6.10099853e-04\n",
      "  2.18336066e-03 -3.79707632e-04 -1.38501500e-02 -1.60504481e-02\n",
      "  4.89221318e-02 -3.53733241e-04 -6.31491563e-04  1.74254852e-02\n",
      "  7.00537917e-04 -7.62619593e-04  1.89889210e+02 -9.21111198e-03\n",
      "  1.82965859e-02  7.96031102e-03  1.47479101e-03  1.00063298e-02\n",
      "  2.30455444e-04 -3.84925914e-03 -2.91992065e-02  6.31294402e-04\n",
      " -5.83427643e-03  9.56267826e-03  2.67813328e-02  1.00913256e-02\n",
      " -6.23720001e-03 -1.66025009e-02 -1.53207500e-03 -9.60052673e-03\n",
      " -2.85748956e-02 -2.94577334e-05 -2.09764595e-03 -2.02235377e-04\n",
      " -1.09688513e-02 -2.03131101e-02 -5.79415916e-03  3.83367504e-02\n",
      " -1.11026240e-04 -3.90589551e-04  2.07797134e-02 -4.22502951e-04\n",
      "  1.18963991e-02]\n"
     ]
    }
   ],
   "source": [
    "w_LS, loss_tr = least_squares(y_tr, tx_tr)\n",
    "loss_te = compute_mse(y_te, tx_te, w_LS)\n",
    "print(f\"Training loss: {loss_tr}\\nTest loss: {loss_te}\\nw: {w_LS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557525a",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "741e5c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.17758079539317778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "w_REG, loss_tr = ridge_regression(y_tr, tx_tr, lambda_)\n",
    "print(f\"Training loss: {loss}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d88db",
   "metadata": {},
   "source": [
    "### Logistic regression using gradient descent or SGD (y ∈ {0, 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038db552",
   "metadata": {},
   "source": [
    "### Regularized logistic regression using gradient descent or SGD (y ∈ {0, 1}, with regularization term λ∥w∥**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d3e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
