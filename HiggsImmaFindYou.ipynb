{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce48c91",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8eeb2",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af40ee",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37127a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a single cell because it takes a long time and doesn't need to be ran everytime\n",
    "y, x = load_data(train=True) # Load data\n",
    "y_indexes, x_test = load_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(x, y, 0.8, np.random.seed())\n",
    "x_tr = replace_min_999_by_col_mean(x_tr) # Handle invalid values\n",
    "x_te = replace_min_999_by_col_mean(x_te)\n",
    "\n",
    "x_tr, mean_x_tr, std_x_tr = standardize(x_tr) # Standardize x\n",
    "x_te, mean_x_te, std_x_te = standardize(x_te)\n",
    "\n",
    "tx_tr = build_poly(x_tr, 2) # build polynomial expansion (with bias)\n",
    "tx_te = build_poly(x_te, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04e81f",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run GD step times per epoch, for epochs epochs (same as running GD for epochs*step just lets us print intermediate results)\n",
    "w_GD, epochs, step, gamma = np.zeros(61), 100, 100, 1e-4\n",
    "loss_tr_GD = []\n",
    "loss_te_GD = []\n",
    "for i in range((int)(epochs)):\n",
    "    w_GD, loss_tr = mean_squared_error_gd(y_tr, tx_tr, w_GD, step, gamma)\n",
    "    loss_te = compute_mse(y_te, tx_te, w_GD)\n",
    "    loss_tr_GD.append(loss_tr)\n",
    "    loss_te_GD.append(loss_te)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a94377",
   "metadata": {},
   "source": [
    "#### Plotting the resulting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(loss_tr_GD)), loss_tr_GD, c='red')\n",
    "plt.plot(range(len(loss_te_GD)), loss_te_GD, c='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549d116",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = -1 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ed80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = compute_accuracy(tx_te, y_te, w_GD, 0)\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test, mean_x_test, std_x_test = standardize(x_test) # Standardize x\n",
    "\n",
    "tx_test = build_poly(x_test, 2) # build polynomial expansion (with bias)\n",
    "\n",
    "y_hat = build_prediction(tx_test, w_GD, 0.4) # threshold of 0.4 found experimentally - mention in report\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9588c",
   "metadata": {},
   "source": [
    "### Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40630c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_SGD, epochs, step, gamma = np.zeros(61), 100, 100, 1e-4\n",
    "for i in range((int)(epochs)):\n",
    "    w_SGD, loss_tr = mean_squared_error_sgd(y_tr, tx_tr, w_SGD, step, gamma)\n",
    "    loss_te = compute_mse(y_te, tx_te, w_SGD)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120442c2",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac680a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_cont = tx_te@w_SGD\n",
    "y_hat = [1 if yi > 0.40 else 0 for yi in y_hat_cont]\n",
    "accuracy = 1-abs(y_te-y_hat).mean()\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c498d12",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_LS, loss_tr = least_squares(y_tr, tx_tr)\n",
    "loss_te = compute_mse(y_te, tx_te, w_LS)\n",
    "print(f\"Training loss: {loss_tr}\\nTest loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cde125",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_cont = tx_te@w_LS\n",
    "y_hat = [1 if yi > 0.45 else 0 for yi in y_hat_cont]\n",
    "accuracy = 1-abs(y_te-y_hat).mean()\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557525a",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.1\n",
    "w_REG, loss_tr = ridge_regression(y_tr, tx_tr, lambda_)\n",
    "print(f\"Training loss: {loss_tr}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_cont = tx_te@w_REG\n",
    "y_hat = [1 if yi > 0.44 else 0 for yi in y_hat_cont]\n",
    "accuracy = 1-abs(y_te-y_hat).mean()\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d88db",
   "metadata": {},
   "source": [
    "### Logistic regression using gradient descent or SGD (y ∈ {0, 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run GD step times per epoch, for epochs epochs (same as running GD for epochs*step just lets us print intermediate results)\n",
    "w_GD_log, epochs, step, gamma = np.zeros(61), 100, 50, 1e-2\n",
    "loss_tr_GD_log = []\n",
    "loss_te_GD_log = []\n",
    "for i in range((int)(epochs)):\n",
    "    w_GD_log, loss_tr = logistic_regression(y_tr, tx_tr, w_GD_log, step, gamma) # TODO this leads to some NaNs\n",
    "    loss_te = compute_log_loss(y_te, tx_te, w_GD_log)\n",
    "    loss_tr_GD_log.append(loss_tr)\n",
    "    loss_te_GD_log.append(loss_te)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c9446",
   "metadata": {},
   "source": [
    "#### Plotting the resulting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5adc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(loss_tr_GD_log)), loss_tr_GD_log, c='red')\n",
    "plt.plot(range(len(loss_te_GD_log)), loss_te_GD_log, c='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f5f37",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = -1 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efad889",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = compute_accuracy_log(tx_te, y_te, w_GD_log, threshold=0.5)\n",
    "print(f\"Accuracy for these w: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test, mean_x_test, std_x_test = standardize(x_test) # Standardize x\n",
    "\n",
    "tx_test = build_poly(x_test, 2)\n",
    "\n",
    "y_hat = build_prediction_log(tx_test, w_GD_log, threshold=0.5, minus_one = True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038db552",
   "metadata": {},
   "source": [
    "### Regularized logistic regression using gradient descent or SGD (y ∈ {0, 1}, with regularization term λ∥w∥**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d3e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
