{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce48c91",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8eeb2",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af40ee",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "37127a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a long time; only run once\n",
    "LOAD_DATA_MODE = {0: \"DER\", 1: \"PRI\", 2: \"ALL\"} # Allows us to switch between DER/PLI values or all\n",
    "y, x = load_data(train=True, mode = LOAD_DATA_MODE[0]) # Load data (DER)\n",
    "y_indexes, x_test = load_data(train=False, mode = LOAD_DATA_MODE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b9e2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(x, y, 0.8, np.random.seed())\n",
    "x_tr = replace_min_999_by_col_mean(x_tr) # Handle invalid values\n",
    "x_te = replace_min_999_by_col_mean(x_te)\n",
    "\n",
    "x_tr = build_poly_2(x_tr) # Poly exp deg=2\n",
    "x_te = build_poly_2(x_te)\n",
    "\n",
    "x_tr, mean_x_tr, std_x_tr = standardize(x_tr) # Standardize x\n",
    "x_te, mean_x_te, std_x_te = standardize(x_te)\n",
    "\n",
    "tx_tr = add_x_bias(x_tr) # Add bias after normalisation to avoid NaNs\n",
    "tx_te = add_x_bias(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e399d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 105)\n",
      "(50000, 105)\n"
     ]
    }
   ],
   "source": [
    "print(tx_tr.shape)\n",
    "print(tx_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04e81f",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baccc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We run GD step times per epoch, for epochs epochs (same as running GD for epochs*step just lets us print intermediate results)\n",
    "w_GD, epochs, step, gamma = np.zeros(105), 100, 150, 1e-2\n",
    "loss_tr_GD = []\n",
    "loss_te_GD = []\n",
    "for i in range((int)(epochs)):\n",
    "    w_GD, loss_tr = mean_squared_error_gd(y_tr, tx_tr, w_GD, step, gamma)\n",
    "    loss_te = compute_mse(y_te, tx_te, w_GD)\n",
    "    loss_tr_GD.append(loss_tr)\n",
    "    loss_te_GD.append(loss_te)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a94377",
   "metadata": {},
   "source": [
    "#### Plotting the resulting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(loss_tr_GD)), loss_tr_GD, c='red')\n",
    "plt.plot(range(len(loss_te_GD)), loss_te_GD, c='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549d116",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc226dea-116f-487b-b114-1050791d8f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_threshold, best_accruacy = threshold_selection_and_plot(tx_te, y_te, w_GD)\n",
    "print(\"best threshold=\", best_threshold,\"\\nbest accruacy=\",best_accruacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53eef6",
   "metadata": {},
   "source": [
    "#### Saving for a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_GD = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test_GD = build_poly_2(x_test_GD) # Build polynomial expansion\n",
    "\n",
    "x_test_GD, mean_x_test_GD, std_x_test_GD = standardize(x_test_GD) # Standardize x\n",
    "\n",
    "tx_test_GD = add_x_bias(x_test_GD)\n",
    "\n",
    "y_hat = build_prediction(tx_test_GD, w_GD, 0.38, True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\") # Accuracy 0.745 F1 0.573"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9588c",
   "metadata": {},
   "source": [
    "### Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40630c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_SGD, epochs, step, gamma = np.zeros(105), 100, 150, 1e-2\n",
    "for i in range((int)(epochs)):\n",
    "    w_SGD, loss_tr = mean_squared_error_sgd(y_tr, tx_tr, w_SGD, step, gamma)\n",
    "    loss_te = compute_mse(y_te, tx_te, w_SGD)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120442c2",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569050d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_threshold, best_accruacy = threshold_selection_and_plot(tx_te, y_te, w_SGD)\n",
    "print(\"best threshold=\", best_threshold,\"\\nbest accruacy=\",best_accruacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937872e1",
   "metadata": {},
   "source": [
    "#### Saving for a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ff833",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_SGD = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test_SGD = build_poly_2(x_test_SGD) # Build polynomial expansion\n",
    "\n",
    "x_test_SGD, mean_x_test_SGD, std_x_test_SGD = standardize(x_test_SGD) # Standardize x\n",
    "\n",
    "tx_test_SGD = add_x_bias(x_test_SGD)\n",
    "\n",
    "y_hat = build_prediction(tx_test_SGD, w_SGD, 0.3783, True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\") # Accuracy 0.753 F1 0.598"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c498d12",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_LS, loss_tr = least_squares(y_tr, tx_tr)\n",
    "loss_te = compute_mse(y_te, tx_te, w_LS)\n",
    "print(f\"Training loss: {loss_tr}\\nTest loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06b40-a347-4c8b-b4d0-e6bda402883e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_threshold, best_accruacy = threshold_selection_and_plot(tx_te, y_te, w_LS)\n",
    "print(\"best threshold=\", best_threshold,\"\\nbest accruacy=\",best_accruacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d6770",
   "metadata": {},
   "source": [
    "#### Saving for a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6742da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_LS = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test_LS = build_poly_2(x_test_LS) # Build polynomial expansion\n",
    "\n",
    "x_test_LS, mean_x_test_LS, std_x_test_LS = standardize(x_test_LS) # Standardize x\n",
    "\n",
    "tx_test_LS = add_x_bias(x_test_LS)\n",
    "\n",
    "y_hat = build_prediction(tx_test_LS, w_LS, 0.3783, True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\") # Accuracy 0.748 F1 0.684"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557525a",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.00233\n",
    "w_REG, loss_tr = ridge_regression(y_tr, tx_tr, lambda_)\n",
    "print(f\"Training loss: {loss_tr}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54c606-5809-41f9-9e70-a2134e9c0632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (very) Long running\n",
    "ridge_lambdas_and_threshold (y_tr, tx_tr, y_te, tx_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85694b8",
   "metadata": {},
   "source": [
    "#### Saving for a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_REG = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test_REG = build_poly_2(x_test_REG) # Build polynomial expansion\n",
    "\n",
    "x_test_REG, mean_x_test_REG, std_x_test_REG = standardize(x_test_REG) # Standardize x\n",
    "\n",
    "tx_test_REG = add_x_bias(x_test_REG)\n",
    "\n",
    "y_hat = build_prediction(tx_test_REG, w_REG, 0.4854, True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\") # Accuracy 0.778 F1 0.654"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d88db",
   "metadata": {},
   "source": [
    "### Logistic regression using gradient descent or SGD (y ∈ {0, 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run GD step times per epoch, for epochs epochs (same as running GD for epochs*step just lets us print intermediate results)\n",
    "w_GD_log, epochs, step, gamma = np.zeros(105), 30, 150, 0.5\n",
    "loss_tr_GD_log = []\n",
    "loss_te_GD_log = []\n",
    "w_GD_log_LIST = []\n",
    "for i in range((int)(epochs)):\n",
    "    w_GD_log, loss_tr = logistic_regression(y_tr, tx_tr, w_GD_log, step, gamma)\n",
    "    loss_te = compute_log_loss(y_te, tx_te, w_GD_log)\n",
    "    loss_tr_GD_log.append(loss_tr)\n",
    "    loss_te_GD_log.append(loss_te)\n",
    "    w_GD_log_LIST.append(w_GD_log)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c9446",
   "metadata": {},
   "source": [
    "#### Plotting the resulting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5adc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(loss_tr_GD_log)), loss_tr_GD_log, c='red')\n",
    "plt.plot(range(len(loss_te_GD_log)), loss_te_GD_log, c='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f5f37",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = -1 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dedde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_GD_log = w_GD_log_LIST[np.argmin(loss_te_GD_log)] # Best W\n",
    "\n",
    "best_threshold_log_reg, best_accruacy = threshold_selection_and_plot_log(tx_te, y_te, w_GD_log)\n",
    "print(\"best threshold=\", best_threshold_log_reg,\"\\nbest accruacy=\",best_accruacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_log = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test_log = build_poly_2(x_test_log)\n",
    "\n",
    "x_test_log, mean_x_test_log, std_x_test_log = standardize(x_test_log) # Standardize x\n",
    "\n",
    "tx_test_log = add_x_bias(x_test_log)\n",
    "\n",
    "y_hat = build_prediction_log(tx_test_log, w_GD_log, threshold=best_threshold_log_reg, minus_one = True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\") # Accuracy 0.804 F1 0.697"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038db552",
   "metadata": {},
   "source": [
    "### Regularized logistic regression using gradient descent or SGD (y ∈ {0, 1}, with regularization term λ∥w∥**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run GD step times per epoch, for epochs epochs (same as running GD for epochs*step just lets us print intermediate results)\n",
    "lambda_reg = 1e-4\n",
    "w_GD_reg_log, epochs, step, gamma = np.zeros(105), 30, 150, 0.5\n",
    "loss_tr_GD_reg_log = []\n",
    "loss_te_GD_reg_log = []\n",
    "w_GD_reg_log_LIST = []\n",
    "for i in range((int)(epochs)):\n",
    "    w_GD_reg_log, loss_tr = reg_logistic_regression(y_tr, tx_tr, lambda_reg, w_GD_reg_log, step, gamma)\n",
    "    loss_te = compute_log_loss(y_te, tx_te, w_GD_reg_log)\n",
    "    loss_tr_GD_reg_log.append(loss_tr)\n",
    "    loss_te_GD_reg_log.append(loss_te)\n",
    "    w_GD_reg_log_LIST.append(w_GD_reg_log)\n",
    "    print(f\"Epoch {i} : Training loss: {loss_tr} Test loss: {loss_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eca606",
   "metadata": {},
   "source": [
    "#### Calculating the accuracy on the test set (with predictions = 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(loss_tr_GD_reg_log)), loss_tr_GD_reg_log, c='red')\n",
    "plt.plot(range(len(loss_te_GD_reg_log)), loss_te_GD_reg_log, c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dce020",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_GD_reg_log = w_GD_reg_log_LIST[np.argmin(loss_te_GD_reg_log)] # Best W\n",
    "\n",
    "best_threshold, best_accruacy = threshold_selection_and_plot_log(tx_te, y_te, w_GD_reg_log)\n",
    "print(\"best threshold=\", best_threshold,\"\\nbest accruacy=\",best_accruacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b33c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_reg_log = replace_min_999_by_col_mean(x_test) # Handle invalid values\n",
    "\n",
    "x_test_reg_log = build_poly_2(x_test_reg_log)\n",
    "\n",
    "x_test_reg_log, mean_x_test_reg_log, std_x_test_reg_log = standardize(x_test_reg_log) # Standardize x\n",
    "\n",
    "tx_test_reg_log = add_x_bias(x_test_reg_log)\n",
    "\n",
    "y_hat = build_prediction_log(tx_test_reg_log, w_GD_reg_log, threshold=best_threshold, minus_one = True)\n",
    "write_to_csv(np.column_stack((y_indexes, y_hat)), \"test_output.csv\") # Accuracy 0.804 F1 0.701"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
