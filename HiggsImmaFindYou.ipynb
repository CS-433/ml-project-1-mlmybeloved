{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce48c91",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf590b",
   "metadata": {},
   "source": [
    "## Checking the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c623a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Long running\n",
    "y, x = load_data(train=True)\n",
    "print(f\"First sample: {x[0,:]}\")\n",
    "print(f\"First sample label: {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8ab06",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2974608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some test data\n",
    "testing_y = np.array([1,1,2,2,4])\n",
    "testing_x = np.array([[1],[2],[3],[4],[5]])\n",
    "testing_w = np.array([-0.1, 0.7])\n",
    "\n",
    "print(f\"X:\\n {testing_x}\\n\")\n",
    "testing_sx, testing_mean_x, testing_std_x = standardize(testing_x) # Standardization\n",
    "print(f\"X normalized:\\n {testing_sx}\\n\") \n",
    "testing_tx = add_x_bias(testing_sx) # Adding bias column to X\n",
    "print(f\"X with bias:\\n {testing_tx}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53571c",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE TEST\")\n",
    "print(f\"Got:{compute_mse(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str(4.71))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6857fad",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE TEST\")\n",
    "print(f\"Got:{compute_mae(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str(2.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d79bf",
   "metadata": {},
   "source": [
    "### MSE Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e397eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE Gradient TEST\")\n",
    "print(f\"Got:{compute_mse_gradient(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str([-2.1, -0.29]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1cbe",
   "metadata": {},
   "source": [
    "### MAE Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE Gradient TEST\")\n",
    "print(f\"Got:{compute_mae_gradient(testing_y, testing_tx, testing_w)}\")\n",
    "print(\"Expected:\" + str([-1, -0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8eeb2",
   "metadata": {},
   "source": [
    "## Assigment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39795994",
   "metadata": {},
   "source": [
    "### Replace -999 by col_mean trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea112e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD SOLUTION - DOES IT WORK ?\n",
    "for i in range(np.shape(x)[1] + 1): # Iterate through x to replace -999 by the mean of its column (which is more natural)\n",
    "    col_mean = np.nanmean(np.ma.MaskedArray(x[i, :], mask=(np.array(x[i, :]) == -999)))\n",
    "    x[i] = [xi if xi != -999 else col_mean for xi in x[i, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW SOLUTION - IN replace_min_999_by_col_mean() IN implementations-py\n",
    "test_stuff = np.array([[1.,2.,-999.], [4.,-999.,9.], [1.,-999.,0.]])\n",
    "print(test_stuff)\n",
    "\n",
    "# print(replace_min_999_by_col_mean(test_stuff)) IMPLEMENTATION BELOW\n",
    "\n",
    "mask_999 = np.where(test_stuff == -999, 1, 0) # 1 where -999 are, 0 otherwise\n",
    "for i in range(test_stuff.shape[1]):\n",
    "    col = test_stuff[:, i] # Get column\n",
    "    mask_col = mask_999[:, i] # Get corresponding mask column\n",
    "    col_mean = np.ma.masked_array(col, mask_col).mean(axis=0) # Compute mean without the -999\n",
    "    test_stuff[:, i] = np.where(col == -999, col_mean, col) # Replace -999 by mean or keep column\n",
    "    \n",
    "print(test_stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af40ee",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = load_data(train=True) # Load train data\n",
    "\n",
    "x = replace_min_999_by_col_mean(x) # Handle invalid values\n",
    "x, mean_x, std_x = standardize(x) # Standardize x\n",
    "tx = add_x_bias(x) # Add the bias term in x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04e81f",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w, max_iters, gamma = np.zeros(31), 100, 1e-10\n",
    "w, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)\n",
    "print(f\"Loss: {loss}\\n w: {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9588c",
   "metadata": {},
   "source": [
    "### Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40630c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w, max_iters, gamma = np.zeros(31), 100, 1e-10\n",
    "w, loss = least_squares_SGD(y, tx, initial_w, max_iters, gamma)\n",
    "print(f\"Loss: {loss}\\n w: {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c498d12",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y, tx)\n",
    "print(f\"Loss: {loss}\\n w: {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557525a",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = 1\n",
    "w, mse = ridge_regression(y, tx, lambda_)\n",
    "print(f\"Loss: {loss}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d88db",
   "metadata": {},
   "source": [
    "### Logistic regression using gradient descent or SGD (y ∈ {0, 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038db552",
   "metadata": {},
   "source": [
    "### Regularized logistic regression using gradient descent or SGD (y ∈ {0, 1}, with regularization term λ∥w∥**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d3e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
